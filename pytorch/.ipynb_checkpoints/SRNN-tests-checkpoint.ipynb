{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fluid-separation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: albertigno\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from MyDataset import *\n",
    "import torch, time, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib.gridspec import GridSpec\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print ('Running on: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "later-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.3\n",
    "batch_size = 256 # default 256\n",
    "learning_rate = 1e-4 # default 1e-4\n",
    "time_window = 50 # shd 50, nmnist 25-30\n",
    "dataset_path = r'./../../datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "widespread-webmaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test set...\n",
      "num sample: 2264\n",
      "torch.Size([2264, 50, 700]) torch.Size([2264, 20])\n",
      "loading training set...\n",
      "num sample: 8156\n",
      "torch.Size([8156, 50, 700]) torch.Size([8156, 20])\n",
      "loading data with pytorch\n"
     ]
    }
   ],
   "source": [
    "train_path = dataset_path+'/shd_digits/shd_train.h5'\n",
    "test_path = dataset_path+'/shd_digits/shd_test.h5'\n",
    "# load datasets\n",
    "print(\"loading test set...\")\n",
    "test_dataset = MyDataset(test_path, 'hd_digits', time_window, device)\n",
    "print(\"loading training set...\")\n",
    "train_dataset = MyDataset(train_path, 'hd_digits', time_window, device)\n",
    "print(\"loading data with pytorch\")\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False, drop_last=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "current-fabric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RSNN(\n",
       "  (fc_ih): Linear(in_features=700, out_features=512, bias=False)\n",
       "  (fc_hh): Linear(in_features=512, out_features=512, bias=False)\n",
       "  (fc_ho): Linear(in_features=512, out_features=20, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snn_models import *\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport snn_models\n",
    "\n",
    "num_hidden = 512\n",
    "#tau_m = 'adp'\n",
    "tau_m = 0.8305\n",
    "#snn = RSNN_delay(d='shd', num_hidden=128, thresh=0.3, decay=0.3, batch_size=batch_size, win=50, device=device)\n",
    "snn = RSNN('shd', num_hidden=num_hidden, thresh=0.3, tau_m=tau_m, vreset=0.0, batch_size=batch_size, win=time_window, device=device)\n",
    "snn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "searching-pacific",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shd_rnn_512_0.8305.t7\n"
     ]
    }
   ],
   "source": [
    "# training configuration\n",
    "\n",
    "num_epochs = 20\n",
    "modelname = 'shd_rnn_{}_{}.t7'.format(snn.num_hidden, tau_m)\n",
    "num_samples = train_dataset.images.size()[0]\n",
    "\n",
    "# super pythonic way to extract the parameters that will have 'normal' learning rate\n",
    "base_params = [getattr(snn,name.split('.')[0]).weight for name, _ in snn.state_dict().items() if name[0]=='f']\n",
    "\n",
    "# setting different learning rate for tau_m, if neeeded\n",
    "if tau_m=='adp':\n",
    "    print('tau_m_h ')\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': base_params},\n",
    "        {'params': snn.tau_m_h, 'lr': learning_rate * 10.0},\n",
    "        {'params': snn.tau_m_o, 'lr': learning_rate * 10.0}],\n",
    "        lr=learning_rate)\n",
    "else:    \n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': base_params}],\n",
    "        lr=learning_rate)\n",
    "    \n",
    "act_fun = ActFun.apply\n",
    "print(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comfortable-monthly",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\n",
      "Step [10/31], Loss: 0.49742\n",
      "Step [20/31], Loss: 0.47635\n",
      "Step [30/31], Loss: 0.46394\n",
      "Time elasped: 3.095825672149658\n",
      "Epoch [2/20]\n",
      "Step [10/31], Loss: 0.45163\n",
      "Step [20/31], Loss: 0.44710\n",
      "Step [30/31], Loss: 0.43838\n",
      "Time elasped: 2.5570240020751953\n",
      "Epoch [3/20]\n",
      "Step [10/31], Loss: 0.42886\n",
      "Step [20/31], Loss: 0.42081\n",
      "Step [30/31], Loss: 0.41358\n",
      "Time elasped: 2.577432155609131\n",
      "Epoch [4/20]\n",
      "Step [10/31], Loss: 0.39738\n",
      "Step [20/31], Loss: 0.39134\n",
      "Step [30/31], Loss: 0.37754\n",
      "Time elasped: 2.520268678665161\n",
      "Epoch [5/20]\n",
      "Step [10/31], Loss: 0.36712\n",
      "Step [20/31], Loss: 0.35484\n",
      "Step [30/31], Loss: 0.34808\n",
      "Time elasped: 2.5787272453308105\n",
      "tensor(12.5007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(25.1501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.7284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(50.2843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(62.9040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.4105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(87.9577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.4704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "avg spk_count per neuron for all 50 timesteps 12.558796882629395\n",
      "Test Accuracy of the model on the test samples: 54.492\n",
      "Epoch [6/20]\n",
      "Step [10/31], Loss: 0.34229\n",
      "Step [20/31], Loss: 0.33866\n",
      "Step [30/31], Loss: 0.34041\n",
      "Time elasped: 2.5760819911956787\n",
      "Epoch [7/20]\n",
      "Step [10/31], Loss: 0.32794\n",
      "Step [20/31], Loss: 0.31823\n",
      "Step [30/31], Loss: 0.31436\n",
      "Time elasped: 2.674736261367798\n",
      "Epoch [8/20]\n",
      "Step [10/31], Loss: 0.30666\n",
      "Step [20/31], Loss: 0.30239\n",
      "Step [30/31], Loss: 0.29735\n",
      "Time elasped: 2.63478422164917\n",
      "Epoch [9/20]\n",
      "Step [10/31], Loss: 0.29853\n",
      "Step [20/31], Loss: 0.31152\n",
      "Step [30/31], Loss: 0.29014\n",
      "Time elasped: 2.6052441596984863\n",
      "Epoch [10/20]\n",
      "Step [10/31], Loss: 0.28583\n",
      "Step [20/31], Loss: 0.27526\n",
      "Step [30/31], Loss: 0.27996\n",
      "Time elasped: 2.616428852081299\n",
      "tensor(14.2226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.6124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.9389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.2316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(71.5452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(85.8382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.1199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.2955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "avg spk_count per neuron for all 50 timesteps 14.286941528320312\n",
      "Test Accuracy of the model on the test samples: 60.547\n",
      "Epoch [11/20]\n",
      "Step [10/31], Loss: 0.27416\n",
      "Step [20/31], Loss: 0.27158\n",
      "Step [30/31], Loss: 0.26721\n",
      "Time elasped: 2.6354353427886963\n",
      "Epoch [12/20]\n",
      "Step [10/31], Loss: 0.25757\n",
      "Step [20/31], Loss: 0.25632\n",
      "Step [30/31], Loss: 0.25172\n",
      "Time elasped: 2.5953593254089355\n",
      "Epoch [13/20]\n",
      "Step [10/31], Loss: 0.25471\n",
      "Step [20/31], Loss: 0.25177\n",
      "Step [30/31], Loss: 0.24875\n",
      "Time elasped: 2.5812788009643555\n",
      "Epoch [14/20]\n",
      "Step [10/31], Loss: 0.24226\n",
      "Step [20/31], Loss: 0.24315\n",
      "Step [30/31], Loss: 0.24179\n",
      "Time elasped: 2.6878092288970947\n",
      "Epoch [15/20]\n",
      "Step [10/31], Loss: 0.23247\n",
      "Step [20/31], Loss: 0.23439\n",
      "Step [30/31], Loss: 0.23514\n",
      "Time elasped: 2.6351606845855713\n",
      "tensor(15.1715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.4888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(45.7664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(61.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(76.2377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(91.4210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.5701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.6401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "avg spk_count per neuron for all 50 timesteps 15.205015182495117\n",
      "Test Accuracy of the model on the test samples: 65.918\n",
      "Epoch [16/20]\n",
      "Step [10/31], Loss: 0.22542\n",
      "Step [20/31], Loss: 0.22781\n",
      "Step [30/31], Loss: 0.22679\n",
      "Time elasped: 2.7291173934936523\n",
      "Epoch [17/20]\n",
      "Step [10/31], Loss: 0.23009\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a56561e40bd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch [%d/%d]'\u001b[0m  \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0msnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time elasped:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\SRNNs\\notebooks\\snn_models.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, train_loader, optimizer, criterion, num_samples, spkreg)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m             \u001b[0mspk_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_sumspike\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mspk_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearnig\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\SRNNs\\notebooks\\snn_models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mh_mem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_spike\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmem_update_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_spike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_spike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_mem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mo_mem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_spike\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmem_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_spike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_spike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_mem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_sumspike\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_sumspike\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_spike\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\SRNNs\\notebooks\\snn_models.py\u001b[0m in \u001b[0;36mmem_update\u001b[1;34m(self, i_spike, o_spike, mem)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmem_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_spike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_spike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau_m_o\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mmem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmem\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mo_spike\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_ho\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_spike\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mo_spike\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvreset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mo_spike\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "taus_m = []\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch [%d/%d]'  % (epoch + 1, num_epochs))\n",
    "    start_time = time.time()\n",
    "    snn.train_step(train_loader, optimizer=optimizer, criterion=nn.MSELoss(), num_samples = num_samples, spkreg=0.1)\n",
    "    t = time.time() - start_time\n",
    "    print('Time elasped:', time.time() - start_time)\n",
    "    \n",
    "    # update learning rate\n",
    "    optimizer = snn.lr_scheduler(optimizer, lr_decay_epoch=1)\n",
    "    \n",
    "    # weight and decay recording\n",
    "    # taus_m.append((snn.tau_m_h.data.detach().clone(), snn.tau_m_o.data.detach().clone()))\n",
    "    \n",
    "    if (epoch+1) % 5 ==0:\n",
    "        snn.test(test_loader, criterion=nn.MSELoss())\n",
    "        #snn.save_model(modelname)   \n",
    "                \n",
    "with open('training_log', 'a') as logs:\n",
    "    logs.write(\"\\nFinished training {} epochs for {}, batch_size {}, time_per_epoch {} s\".format(num_epochs, modelname, batch_size, t))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = snn.plot_weights('hh', 'histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.save_to_numpy(modelname.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "initial_taus = taus_m[0][0].cpu().numpy()\n",
    "final_taus = taus_m[-1][0].cpu().numpy()\n",
    "\n",
    "df = pd.DataFrame(initial_taus, columns=['Epoch 1'])\n",
    "df['Epoch {}'.format(len(taus_m))] = final_taus\n",
    "\n",
    "sns.histplot(data=df, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fig = snn.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RSNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load_model(modelname, 256, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-flash",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_fig = m.plot_loss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
