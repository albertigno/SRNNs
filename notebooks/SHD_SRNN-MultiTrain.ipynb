{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "blind-ancient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: albertigno\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from MyDataset import *\n",
    "import torch, time, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib.gridspec import GridSpec\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print ('Running on: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "primary-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.3\n",
    "batch_size = 256 # default 256\n",
    "learning_rate = 1e-4 # default 1e-4\n",
    "time_window = 50 # shd 50, nmnist 25-30\n",
    "dataset_path = r'./../../datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "given-reviewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test set...\n",
      "num sample: 2264\n",
      "torch.Size([2264, 50, 700]) torch.Size([2264, 20])\n",
      "loading training set...\n",
      "num sample: 8156\n",
      "torch.Size([8156, 50, 700]) torch.Size([8156, 20])\n",
      "loading data with pytorch\n"
     ]
    }
   ],
   "source": [
    "train_path = dataset_path+'/shd_digits/shd_train.h5'\n",
    "test_path = dataset_path+'/shd_digits/shd_test.h5'\n",
    "# load datasets\n",
    "print(\"loading test set...\")\n",
    "test_dataset = MyDataset(test_path, 'hd_digits', time_window, device)\n",
    "print(\"loading training set...\")\n",
    "train_dataset = MyDataset(train_path, 'hd_digits', time_window, device)\n",
    "print(\"loading data with pytorch\")\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False, drop_last=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nasty-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snn_models import *\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport snn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "improving-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "num_epochs = 2\n",
    "import numpy as np\n",
    "\n",
    "tau_m = [0.8305, 'adp']\n",
    "num_hidden = [128, 256, 512, 1024, 2048]\n",
    "delay_mode = ['nodelay','delay']\n",
    "vreset = [0.0, 0.1]\n",
    "\n",
    "num = len(tau_m)*len(num_hidden)*len(delay_mode)*len(vreset)\n",
    "\n",
    "x, y, z, w = np.meshgrid(tau_m, num_hidden, delay_mode, vreset)\n",
    "x=x.reshape(num)\n",
    "y=y.reshape(num)\n",
    "z=z.reshape(num)\n",
    "w=w.reshape(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "generic-cement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------TRAINING shd_rnn_128.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49927\n",
      "Step [20/31], Loss: 0.48631\n",
      "Step [30/31], Loss: 0.47910\n",
      "Time elasped: 2.3439388275146484\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.47254\n",
      "Step [20/31], Loss: 0.46809\n",
      "Step [30/31], Loss: 0.46222\n",
      "Time elasped: 2.32613468170166\n",
      "-------TRAINING shd_rnn_128_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49686\n",
      "Step [20/31], Loss: 0.48454\n",
      "Step [30/31], Loss: 0.47848\n",
      "Time elasped: 2.319868326187134\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.47348\n",
      "Step [20/31], Loss: 0.46686\n",
      "Step [30/31], Loss: 0.46331\n",
      "Time elasped: 2.31793475151062\n",
      "-------TRAINING shd_rnn_128_delay.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.50857\n",
      "Step [20/31], Loss: 0.48011\n",
      "Step [30/31], Loss: 0.47082\n",
      "Time elasped: 2.738070487976074\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.46075\n",
      "Step [20/31], Loss: 0.45167\n",
      "Step [30/31], Loss: 0.44467\n",
      "Time elasped: 2.766993284225464\n",
      "-------TRAINING shd_rnn_128_delay_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.50585\n",
      "Step [20/31], Loss: 0.48228\n",
      "Step [30/31], Loss: 0.47103\n",
      "Time elasped: 2.784510374069214\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.45927\n",
      "Step [20/31], Loss: 0.45081\n",
      "Step [30/31], Loss: 0.44306\n",
      "Time elasped: 2.791836738586426\n",
      "-------TRAINING shd_rnn_128_adp.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.51275\n",
      "Step [20/31], Loss: 0.48936\n",
      "Step [30/31], Loss: 0.48269\n",
      "Time elasped: 2.545276403427124\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.47867\n",
      "Step [20/31], Loss: 0.46963\n",
      "Step [30/31], Loss: 0.46596\n",
      "Time elasped: 2.509730339050293\n",
      "-------TRAINING shd_rnn_128_adp_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49866\n",
      "Step [20/31], Loss: 0.48608\n",
      "Step [30/31], Loss: 0.47951\n",
      "Time elasped: 2.5067861080169678\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.47147\n",
      "Step [20/31], Loss: 0.46870\n",
      "Step [30/31], Loss: 0.46208\n",
      "Time elasped: 2.5045292377471924\n",
      "-------TRAINING shd_rnn_128_adp_delay.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.51934\n",
      "Step [20/31], Loss: 0.48728\n",
      "Step [30/31], Loss: 0.47885\n",
      "Time elasped: 2.858403205871582\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.46952\n",
      "Step [20/31], Loss: 0.46105\n",
      "Step [30/31], Loss: 0.45219\n",
      "Time elasped: 2.8333559036254883\n",
      "-------TRAINING shd_rnn_128_adp_delay_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.50217\n",
      "Step [20/31], Loss: 0.48310\n",
      "Step [30/31], Loss: 0.47420\n",
      "Time elasped: 2.8693809509277344\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.46312\n",
      "Step [20/31], Loss: 0.45717\n",
      "Step [30/31], Loss: 0.44753\n",
      "Time elasped: 2.791071653366089\n",
      "-------TRAINING shd_rnn_256.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49434\n",
      "Step [20/31], Loss: 0.48131\n",
      "Step [30/31], Loss: 0.47244\n",
      "Time elasped: 2.304935932159424\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.46180\n",
      "Step [20/31], Loss: 0.45446\n",
      "Step [30/31], Loss: 0.44887\n",
      "Time elasped: 2.327049732208252\n",
      "-------TRAINING shd_rnn_256_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49809\n",
      "Step [20/31], Loss: 0.48201\n",
      "Step [30/31], Loss: 0.47531\n",
      "Time elasped: 2.3075408935546875\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.46798\n",
      "Step [20/31], Loss: 0.46383\n",
      "Step [30/31], Loss: 0.45806\n",
      "Time elasped: 2.302881956100464\n",
      "-------TRAINING shd_rnn_256_delay.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.50611\n",
      "Step [20/31], Loss: 0.47828\n",
      "Step [30/31], Loss: 0.46353\n",
      "Time elasped: 2.7470762729644775\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.45241\n",
      "Step [20/31], Loss: 0.44153\n",
      "Step [30/31], Loss: 0.43070\n",
      "Time elasped: 2.721208333969116\n",
      "-------TRAINING shd_rnn_256_delay_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.50068\n",
      "Step [20/31], Loss: 0.47841\n",
      "Step [30/31], Loss: 0.46401\n",
      "Time elasped: 2.7112174034118652\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.44996\n",
      "Step [20/31], Loss: 0.44034\n",
      "Step [30/31], Loss: 0.43467\n",
      "Time elasped: 2.7005250453948975\n",
      "-------TRAINING shd_rnn_256_adp.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49506\n",
      "Step [20/31], Loss: 0.48239\n",
      "Step [30/31], Loss: 0.47376\n",
      "Time elasped: 2.4597620964050293\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.46640\n",
      "Step [20/31], Loss: 0.45596\n",
      "Step [30/31], Loss: 0.44767\n",
      "Time elasped: 2.450839042663574\n",
      "-------TRAINING shd_rnn_256_adp_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49187\n",
      "Step [20/31], Loss: 0.47636\n",
      "Step [30/31], Loss: 0.46814\n",
      "Time elasped: 2.4385409355163574\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.45798\n",
      "Step [20/31], Loss: 0.45237\n",
      "Step [30/31], Loss: 0.44805\n",
      "Time elasped: 2.4382505416870117\n",
      "-------TRAINING shd_rnn_256_adp_delay.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49980\n",
      "Step [20/31], Loss: 0.47690\n",
      "Step [30/31], Loss: 0.46110\n",
      "Time elasped: 2.797238826751709\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.44519\n",
      "Step [20/31], Loss: 0.43512\n",
      "Step [30/31], Loss: 0.42520\n",
      "Time elasped: 2.815430164337158\n",
      "-------TRAINING shd_rnn_256_adp_delay_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.50346\n",
      "Step [20/31], Loss: 0.48079\n",
      "Step [30/31], Loss: 0.46977\n",
      "Time elasped: 2.8009915351867676\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.45636\n",
      "Step [20/31], Loss: 0.44799\n",
      "Step [30/31], Loss: 0.43732\n",
      "Time elasped: 2.8362157344818115\n",
      "-------TRAINING shd_rnn_512.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49598\n",
      "Step [20/31], Loss: 0.48043\n",
      "Step [30/31], Loss: 0.46957\n",
      "Time elasped: 2.312901020050049\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.45674\n",
      "Step [20/31], Loss: 0.44920\n",
      "Step [30/31], Loss: 0.43853\n",
      "Time elasped: 2.3444337844848633\n",
      "-------TRAINING shd_rnn_512_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49334\n",
      "Step [20/31], Loss: 0.47933\n",
      "Step [30/31], Loss: 0.46753\n",
      "Time elasped: 2.4126877784729004\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.45788\n",
      "Step [20/31], Loss: 0.45030\n",
      "Step [30/31], Loss: 0.44172\n",
      "Time elasped: 2.460508346557617\n",
      "-------TRAINING shd_rnn_512_delay.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.52491\n",
      "Step [20/31], Loss: 0.48118\n",
      "Step [30/31], Loss: 0.46710\n",
      "Time elasped: 2.9956464767456055\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.45044\n",
      "Step [20/31], Loss: 0.44162\n",
      "Step [30/31], Loss: 0.42734\n",
      "Time elasped: 2.8868043422698975\n",
      "-------TRAINING shd_rnn_512_delay_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.50671\n",
      "Step [20/31], Loss: 0.47344\n",
      "Step [30/31], Loss: 0.45587\n",
      "Time elasped: 2.864287853240967\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.44067\n",
      "Step [20/31], Loss: 0.43039\n",
      "Step [30/31], Loss: 0.42404\n",
      "Time elasped: 2.881105661392212\n",
      "-------TRAINING shd_rnn_512_adp.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.50081\n",
      "Step [20/31], Loss: 0.47774\n",
      "Step [30/31], Loss: 0.46766\n",
      "Time elasped: 2.4986166954040527\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.45469\n",
      "Step [20/31], Loss: 0.44852\n",
      "Step [30/31], Loss: 0.44373\n",
      "Time elasped: 2.4880552291870117\n",
      "-------TRAINING shd_rnn_512_adp_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.51634\n",
      "Step [20/31], Loss: 0.48159\n",
      "Step [30/31], Loss: 0.47278\n",
      "Time elasped: 2.509230136871338\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.46584\n",
      "Step [20/31], Loss: 0.45886\n",
      "Step [30/31], Loss: 0.45238\n",
      "Time elasped: 2.4974968433380127\n",
      "-------TRAINING shd_rnn_512_adp_delay.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.48999\n",
      "Step [20/31], Loss: 0.46190\n",
      "Step [30/31], Loss: 0.44981\n",
      "Time elasped: 2.8570942878723145\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.43087\n",
      "Step [20/31], Loss: 0.41821\n",
      "Step [30/31], Loss: 0.40793\n",
      "Time elasped: 2.8476486206054688\n",
      "-------TRAINING shd_rnn_512_adp_delay_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49792\n",
      "Step [20/31], Loss: 0.47237\n",
      "Step [30/31], Loss: 0.45545\n",
      "Time elasped: 2.857215166091919\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.44174\n",
      "Step [20/31], Loss: 0.42852\n",
      "Step [30/31], Loss: 0.42136\n",
      "Time elasped: 2.8809502124786377\n",
      "-------TRAINING shd_rnn_1024.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49984\n",
      "Step [20/31], Loss: 0.47346\n",
      "Step [30/31], Loss: 0.46398\n",
      "Time elasped: 2.4019570350646973\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.45052\n",
      "Step [20/31], Loss: 0.44060\n",
      "Step [30/31], Loss: 0.43596\n",
      "Time elasped: 2.4170989990234375\n",
      "-------TRAINING shd_rnn_1024_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49168\n",
      "Step [20/31], Loss: 0.46767\n",
      "Step [30/31], Loss: 0.45554\n",
      "Time elasped: 2.386232614517212\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.44421\n",
      "Step [20/31], Loss: 0.43550\n",
      "Step [30/31], Loss: 0.42748\n",
      "Time elasped: 2.3961102962493896\n",
      "-------TRAINING shd_rnn_1024_delay.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.52262\n",
      "Step [20/31], Loss: 0.46892\n",
      "Step [30/31], Loss: 0.45018\n",
      "Time elasped: 2.936236619949341\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.43310\n",
      "Step [20/31], Loss: 0.42416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [30/31], Loss: 0.41881\n",
      "Time elasped: 2.941969633102417\n",
      "-------TRAINING shd_rnn_1024_delay_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.50818\n",
      "Step [20/31], Loss: 0.47183\n",
      "Step [30/31], Loss: 0.45459\n",
      "Time elasped: 2.974759101867676\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.43798\n",
      "Step [20/31], Loss: 0.42740\n",
      "Step [30/31], Loss: 0.41747\n",
      "Time elasped: 3.0005455017089844\n",
      "-------TRAINING shd_rnn_1024_adp.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.48581\n",
      "Step [20/31], Loss: 0.46238\n",
      "Step [30/31], Loss: 0.45026\n",
      "Time elasped: 2.5092031955718994\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.43485\n",
      "Step [20/31], Loss: 0.42040\n",
      "Step [30/31], Loss: 0.40836\n",
      "Time elasped: 2.4746077060699463\n",
      "-------TRAINING shd_rnn_1024_adp_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49562\n",
      "Step [20/31], Loss: 0.47496\n",
      "Step [30/31], Loss: 0.46031\n",
      "Time elasped: 2.485018253326416\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.45110\n",
      "Step [20/31], Loss: 0.44131\n",
      "Step [30/31], Loss: 0.43353\n",
      "Time elasped: 2.499577522277832\n",
      "-------TRAINING shd_rnn_1024_adp_delay.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.52280\n",
      "Step [20/31], Loss: 0.47181\n",
      "Step [30/31], Loss: 0.45519\n",
      "Time elasped: 2.796865224838257\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.44484\n",
      "Step [20/31], Loss: 0.43209\n",
      "Step [30/31], Loss: 0.42199\n",
      "Time elasped: 2.830826759338379\n",
      "-------TRAINING shd_rnn_1024_adp_delay_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.50211\n",
      "Step [20/31], Loss: 0.46427\n",
      "Step [30/31], Loss: 0.44841\n",
      "Time elasped: 2.8616654872894287\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.43239\n",
      "Step [20/31], Loss: 0.42258\n",
      "Step [30/31], Loss: 0.41379\n",
      "Time elasped: 2.8073678016662598\n",
      "-------TRAINING shd_rnn_2048.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.51289\n",
      "Step [20/31], Loss: 0.48554\n",
      "Step [30/31], Loss: 0.47297\n",
      "Time elasped: 3.5902607440948486\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.46687\n",
      "Step [20/31], Loss: 0.45944\n",
      "Step [30/31], Loss: 0.45215\n",
      "Time elasped: 3.6186094284057617\n",
      "-------TRAINING shd_rnn_2048_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49269\n",
      "Step [20/31], Loss: 0.47023\n",
      "Step [30/31], Loss: 0.45817\n",
      "Time elasped: 3.683856248855591\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.44274\n",
      "Step [20/31], Loss: 0.42929\n",
      "Step [30/31], Loss: 0.41616\n",
      "Time elasped: 3.662271738052368\n",
      "-------TRAINING shd_rnn_2048_delay.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.51817\n",
      "Step [20/31], Loss: 0.47629\n",
      "Step [30/31], Loss: 0.46096\n",
      "Time elasped: 4.543995141983032\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.44846\n",
      "Step [20/31], Loss: 0.44609\n",
      "Step [30/31], Loss: 0.44014\n",
      "Time elasped: 4.553478479385376\n",
      "-------TRAINING shd_rnn_2048_delay_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49252\n",
      "Step [20/31], Loss: 0.46822\n",
      "Step [30/31], Loss: 0.44684\n",
      "Time elasped: 4.522417783737183\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.43431\n",
      "Step [20/31], Loss: 0.42205\n",
      "Step [30/31], Loss: 0.41881\n",
      "Time elasped: 4.560187101364136\n",
      "-------TRAINING shd_rnn_2048_adp.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49961\n",
      "Step [20/31], Loss: 0.47637\n",
      "Step [30/31], Loss: 0.46841\n",
      "Time elasped: 3.093696117401123\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.45425\n",
      "Step [20/31], Loss: 0.45155\n",
      "Step [30/31], Loss: 0.43946\n",
      "Time elasped: 3.111053705215454\n",
      "-------TRAINING shd_rnn_2048_adp_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49069\n",
      "Step [20/31], Loss: 0.47004\n",
      "Step [30/31], Loss: 0.45699\n",
      "Time elasped: 3.087337017059326\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.44098\n",
      "Step [20/31], Loss: 0.43278\n",
      "Step [30/31], Loss: 0.42537\n",
      "Time elasped: 3.1142196655273438\n",
      "-------TRAINING shd_rnn_2048_adp_delay.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.52230\n",
      "Step [20/31], Loss: 0.47121\n",
      "Step [30/31], Loss: 0.45979\n",
      "Time elasped: 3.887084722518921\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.44665\n",
      "Step [20/31], Loss: 0.43568\n",
      "Step [30/31], Loss: 0.42762\n",
      "Time elasped: 3.9044651985168457\n",
      "-------TRAINING shd_rnn_2048_adp_delay_vreset.t7 ---------\n",
      "Epoch [1/2]\n",
      "Step [10/31], Loss: 0.49370\n",
      "Step [20/31], Loss: 0.46595\n",
      "Step [30/31], Loss: 0.45728\n",
      "Time elasped: 3.896879196166992\n",
      "Epoch [2/2]\n",
      "Step [10/31], Loss: 0.44259\n",
      "Step [20/31], Loss: 0.43283\n",
      "Step [30/31], Loss: 0.42851\n",
      "Time elasped: 3.9526865482330322\n"
     ]
    }
   ],
   "source": [
    "for i in range(num):\n",
    "\n",
    "    if x[i]!='adp':\n",
    "        tau_m = float(x[i]) \n",
    "    else:\n",
    "        tau_m = x[i]\n",
    "    num_hidden = int(y[i])\n",
    "    delay_mode = z[i]\n",
    "    vreset = float(w[i])\n",
    "\n",
    "    #tau_m = 0.8305\n",
    "    #snn = RSNN_delay(d='shd', num_hidden=128, thresh=0.3, decay=0.3, batch_size=batch_size, win=50, device=device)\n",
    "    \n",
    "    if delay_mode == 'nodelay':\n",
    "        delay_name = ''\n",
    "        snn = RSNN('shd', num_hidden=num_hidden, thresh=0.3, tau_m=tau_m, vreset=vreset, batch_size=batch_size, win=time_window, device=device)\n",
    "    else:\n",
    "        delay_name = '_delay'\n",
    "        snn = RSNN_d('shd', num_hidden=num_hidden, thresh=0.3, tau_m=tau_m, vreset=vreset, batch_size=batch_size, win=time_window, device=device)\n",
    "\n",
    "    snn.to(device)\n",
    "    \n",
    "    if tau_m != 'adp':\n",
    "        tau_name = ''\n",
    "    else:\n",
    "        tau_name = '_adp'\n",
    "        \n",
    "    if vreset==0:\n",
    "        vreset_name = ''\n",
    "    else:\n",
    "        vreset_name = '_vreset'\n",
    "        \n",
    "    # training configuration\n",
    "    modelname = 'shd_rnn_{}{}{}{}.t7'.format(snn.num_hidden, tau_name, delay_name, vreset_name)\n",
    "    \n",
    "    print(\"-------TRAINING {} ---------\".format(modelname))\n",
    "    num_samples = train_dataset.images.size()[0]\n",
    "\n",
    "    # super pythonic way to extract the parameters that will have 'normal' learning rate\n",
    "    base_params = [getattr(snn,name.split('.')[0]).weight for name, _ in snn.state_dict().items() if name[0]=='f']\n",
    "\n",
    "    # setting different learning rate for tau_m, if neeeded\n",
    "    if tau_m=='adp':\n",
    "        optimizer = torch.optim.Adam([\n",
    "            {'params': base_params},\n",
    "            {'params': snn.tau_m_h, 'lr': learning_rate * 10.0}],\n",
    "            lr=learning_rate)\n",
    "    else:    \n",
    "        optimizer = torch.optim.Adam([\n",
    "            {'params': base_params}],\n",
    "            lr=learning_rate)\n",
    "\n",
    "    act_fun = ActFun.apply\n",
    "\n",
    "\n",
    "    # training loop\n",
    "    taus_m = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch [%d/%d]'  % (epoch + 1, num_epochs))\n",
    "        start_time = time.time()\n",
    "        snn.train_step(train_loader, optimizer=optimizer, criterion=nn.MSELoss(), num_samples = num_samples)\n",
    "        t = time.time() - start_time\n",
    "        print('Time elasped:', time.time() - start_time)\n",
    "\n",
    "        # update learning rate\n",
    "        optimizer = snn.lr_scheduler(optimizer, lr_decay_epoch=1)\n",
    "\n",
    "        # weight and decay recording\n",
    "        # taus_m.append((snn.tau_m_h.data.detach().clone(), snn.tau_m_o.data.detach().clone()))\n",
    "\n",
    "        if (epoch+1) % 5 ==0:\n",
    "            snn.test(test_loader, criterion=nn.MSELoss())\n",
    "            snn.save_model(modelname)   \n",
    "\n",
    "    with open('training_log', 'a') as logs:\n",
    "        logs.write(\"\\nFinished training {} epochs for {}, batch_size {}, time_per_epoch {} s\".format(num_epochs, modelname, batch_size, t))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "legislative-spelling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "raising-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load_model(modelname, 256, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
