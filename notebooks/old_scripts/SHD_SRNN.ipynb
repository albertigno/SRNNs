{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regular-clothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: albertigno\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from MyLargeDataset import *\n",
    "import torch, time, os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "owned-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "thresh = 0.3\n",
    "lens = 0.25\n",
    "decay = 0.3\n",
    "num_classes = 20\n",
    "batch_size = 256\n",
    "learning_rate = 1e-4\n",
    "#learning_rate = 2e-4\n",
    "time_window = 100\n",
    "\n",
    "dataset_path = r'./../../datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "level-examination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n",
      "loading test set...\n",
      "torch.Size([2264, 100, 700])\n",
      "torch.Size([2264])\n",
      "num sample: 2264\n",
      "torch.Size([2264, 100, 700]) torch.Size([2264, 20])\n",
      "loading training set...\n",
      "torch.Size([8156, 100, 700])\n",
      "torch.Size([8156])\n",
      "num sample: 8156\n",
      "torch.Size([8156, 100, 700]) torch.Size([8156, 20])\n",
      "loading data with pytorch\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)\n",
    "train_path = dataset_path+'/shd_digits/shd_train.h5'\n",
    "test_path = dataset_path+'/shd_digits/shd_test.h5'\n",
    "# load datasets\n",
    "print(\"loading test set...\")\n",
    "test_dataset = MyDataset(test_path, 'hd_digits', time_window)\n",
    "print(\"loading training set...\")\n",
    "train_dataset = MyDataset(train_path, 'hd_digits', time_window)\n",
    "print(\"loading data with pytorch\")\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False, drop_last=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suitable-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActFun(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.gt(thresh).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        temp = abs(input - thresh) < lens\n",
    "        return grad_input * temp.float() / (2 * lens)\n",
    "\n",
    "num_hidden = 256\n",
    "num_output = 20\n",
    "\n",
    "best_acc = 0\n",
    "acc_record = list([])\n",
    "\n",
    "class SNN_Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=20):\n",
    "        super(SNN_Model, self).__init__()\n",
    "        \n",
    "        self.fc_ih = nn.Linear(700, num_hidden, bias= False)\n",
    "        self.fc_hh = nn.Linear(num_hidden, num_hidden, bias= False)\n",
    "        self.fc_ho = nn.Linear(num_hidden, num_output, bias= False)\n",
    "        \n",
    "    def forward(self, input, win):\n",
    "        \n",
    "        h0_mem = h0_spike = h0_sumspike = torch.zeros(1, batch_size, num_hidden, device=device)\n",
    "        h2_mem = h2_spike = h2_sumspike = torch.zeros(1, batch_size, num_output, device=device)\n",
    "        \n",
    "        dense_input = input.to_dense()\n",
    "        dense_input = 1*(dense_input > 0).float()\n",
    "        \n",
    "        for step in range(win):\n",
    "            \n",
    "            x = dense_input[:, step, :]\n",
    "            x = x.view(1, batch_size, -1)\n",
    "\n",
    "            h0_mem, h0_spike = mem_update_rnn(self.fc_ih, self.fc_hh, x, h0_spike, h0_mem, h0_spike)\n",
    "                        \n",
    "            h2_mem, h2_spike = mem_update(self.fc_ho, h0_spike, h2_mem, h2_spike)\n",
    "\n",
    "            h2_sumspike += h2_spike\n",
    "        \n",
    "        outputs = h2_sumspike / (win)\n",
    "        \n",
    "        return outputs[0]    \n",
    "    \n",
    "    \n",
    "def mem_update(operation, x, mem, spike):\n",
    "    mem = mem * decay * (1 - spike) + operation(x)\n",
    "    spike = act_fun(mem)\n",
    "    mem = mem*(mem<thresh)\n",
    "    return mem, spike\n",
    "\n",
    "def mem_update_rnn(operation1, operation2, x, h, mem, spike):\n",
    "    a = operation1(x)\n",
    "    b = operation2(h)\n",
    "    c = mem * decay * (1 - spike) \n",
    "    mem = a + b + c\n",
    "    spike = act_fun(mem)\n",
    "    mem = mem*(mem<thresh)\n",
    "    return mem, spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "professional-script",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shd_rnn_256.t7\n"
     ]
    }
   ],
   "source": [
    "snn = SNN_Model()\n",
    "\n",
    "num_epochs = 50\n",
    "    \n",
    "snn.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "modelname = 'shd_rnn_{}.t7'.format(num_hidden)\n",
    "\n",
    "def lr_scheduler(optimizer, epoch, init_lr=0.1, lr_decay_epoch=100):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0 and epoch > 1:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.98\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "optimizer = torch.optim.Adam(snn.parameters(), lr=learning_rate)\n",
    "\n",
    "act_fun = ActFun.apply\n",
    "print(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "colored-median",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iters: 0 \n",
      "\n",
      "\n",
      "\n",
      "Test Accuracy of the model on the test samples: 15.479\n",
      "Train loss: 1.4871536456048489, Test loss: 0.37323398888111115\n",
      "Saving best accuracy so far..\n",
      "15.478515625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e6887c0aee80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0msnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearnig\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearnig\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearnig\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearnig\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\SRNNs\\notebooks\\MyLargeDataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#返回的是tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "win = 50\n",
    "best_acc = 0\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    total_loss_train = 0\n",
    "    start_time = time.time()\n",
    "    total = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        snn.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images = images.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        outputs = snn(images, win)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        total_loss_train += loss.item()\n",
    "        total += labels.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i + 1) % 50 == 0:\n",
    "            # print( outputs.sum(dim=0) )\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.5f'\n",
    "                  % (epoch + 1, num_epochs, i + 1, len(train_dataset) // batch_size, running_loss))\n",
    "            running_loss = 0\n",
    "            print('Time elasped:', time.time() - start_time)\n",
    "    train_loss.append(total_loss_train / total)\n",
    "    \n",
    "    optimizer = lr_scheduler(optimizer, epoch, learning_rate, 1)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss_test = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        outputs = snn(images, win)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, reference = torch.max(labels.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == reference).sum()\n",
    "        total_loss_test += loss.item() \n",
    "\n",
    "    print('Iters:', epoch, '\\n\\n\\n')\n",
    "    print('Test Accuracy of the model on the test samples: %.3f' % (100 * correct.float() / total))\n",
    "    \n",
    "    print('Train loss: {}, Test loss: {}'.format(total_loss_train, total_loss_test))\n",
    "    \n",
    "    acc = 100. * float(correct) / float(total)\n",
    "    acc_record.append(acc)\n",
    "    \n",
    "    test_loss.append(total_loss_test / total)\n",
    "    state = {\n",
    "    'net': snn.state_dict(),\n",
    "    'acc': acc,\n",
    "    'epoch': epoch,\n",
    "    'acc_record': acc_record,\n",
    "    'train_loss': train_loss,\n",
    "    'test_loss': test_loss\n",
    "    }    \n",
    "    \n",
    "    if acc>best_acc:\n",
    "        print('Saving best accuracy so far..')\n",
    "        print(acc)\n",
    "        torch.save(state, './checkpoint/' + modelname,  _use_new_zipfile_serialization=False)\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "optical-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "'net': snn.state_dict(),\n",
    "'acc': acc,\n",
    "    \n",
    "    \n",
    "    \n",
    "'epoch': epoch,\n",
    "'acc_record': acc_record,\n",
    "'train_loss': train_loss,\n",
    "'test_loss': test_loss\n",
    "}    \n",
    "\n",
    "mf = modelname.split('.')[0] + '_final.t7'\n",
    "torch.save(state, './checkpoint/' + mf ,  _use_new_zipfile_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "healthy-democracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23eeb6130f0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss)\n",
    "plt.plot(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "finite-bride",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23e81683860>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss)\n",
    "plt.plot(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assisted-school",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 21.045\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.float().to(device)\n",
    "        outputs = model(images, win)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, labels = torch.max(labels.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.cpu() == labels).sum()\n",
    "    \n",
    "    acc = 100 * correct.float() / total\n",
    "    return acc\n",
    "\n",
    "acc = get_accuracy(snn)\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: %.3f' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "clear-tolerance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading trained model\n",
      "odict_keys(['fc_ih.weight', 'fc_hh.weight', 'fc_ho.weight'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"loading trained model\")\n",
    "model_to_load = modelname\n",
    "\n",
    "#snn_state_dict = torch.load('./checkpoint/'+modelname, map_location=torch.device('cpu'))['net']\n",
    "snn_state_dict = torch.load('./checkpoint/'+model_to_load, map_location=torch.device('cpu'))['net']\n",
    "print(snn_state_dict.keys())\n",
    "\n",
    "layers_location = 'checkpoint/'+model_to_load.split('.')[0]\n",
    "\n",
    "if not os.path.isdir(layers_location):\n",
    "    os.mkdir(layers_location)\n",
    "\n",
    "weights_biases = []\n",
    "for k in snn_state_dict:\n",
    "    np.savez(layers_location+'/'+k,snn_state_dict[k].data.cpu().numpy())\n",
    "    weights_biases.append(snn_state_dict[k].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "recent-tunisia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 26.000\n"
     ]
    }
   ],
   "source": [
    "model_to_load = modelname\n",
    "#model_to_load = 'heidelberg_rnn_400_mem1.t7'\n",
    "snn_state_dict = torch.load('./checkpoint/'+model_to_load, map_location=torch.device('cpu'))['net']\n",
    "\n",
    "model = SNN_Model()\n",
    "model.load_state_dict(snn_state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# run a subset of test set\n",
    "num_to_test = 50\n",
    "for images, labels in test_loader:\n",
    "    images = images.float().to(device)\n",
    "    labels = labels.float().to(device)\n",
    "    outputs = model(images, win)\n",
    "    _, predicted = torch.max(outputs[:num_to_test,:].data, 1)\n",
    "    _, reference = torch.max(labels[:num_to_test,:].data, 1)\n",
    "    correct = (predicted == reference).sum()\n",
    "    break\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: %.3f' % (100 * correct.float() / num_to_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-miracle",
   "metadata": {},
   "source": [
    "#### SpiNNaker: 50 muestras, 58%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
